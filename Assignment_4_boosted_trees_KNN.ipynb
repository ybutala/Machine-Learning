{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14ef477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff94f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = pickle.load(open('listens.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b31a50",
   "metadata": {},
   "source": [
    "## 4.1 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef357658",
   "metadata": {},
   "source": [
    "### (a) How many users and songs are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12b17be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 1960\n",
      "Number of songs: 990\n"
     ]
    }
   ],
   "source": [
    "no_users = X.shape[0]\n",
    "no_songs = X.shape[1]\n",
    "print(\"Number of users:\", no_users)\n",
    "print(\"Number of songs:\", no_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff001d87",
   "metadata": {},
   "source": [
    "### (b) What is the maximum number of times that a user has listened to one song?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a597b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of times that a user has listened to one song: 214.0\n"
     ]
    }
   ],
   "source": [
    "max_listens = np.max(X)\n",
    "print(\"Maximum number of times that a user has listened to one song:\", max_listens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5832b49",
   "metadata": {},
   "source": [
    "### (c) What percentage of users have listened to the special song?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa38a1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of users that have listened to the special song: 16.3265306122449\n"
     ]
    }
   ],
   "source": [
    "special_song_listen = np.sum(y)\n",
    "special_song_listen_percent = (special_song_listen / no_users) * 100\n",
    "print(\"Percentage of users that have listened to the special song:\", special_song_listen_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8cad6",
   "metadata": {},
   "source": [
    "### (d) Count the number of times each song has been listened to. What’s the smallest number? The largest number? The average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626e2072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of times each song has been listened to: 60991.0\n",
      "Smallest number of times each song has been listened to.: 6.0\n",
      "Highest number of times each song has been listened to: 688.0\n",
      "Average number of times each song has been listened to: 61.607070707070704\n"
     ]
    }
   ],
   "source": [
    "song_listens = np.sum(X, axis=0)\n",
    "smallest_songs = np.min(song_listens)\n",
    "largest_songs = np.max(song_listens)\n",
    "avg_songs = np.mean(song_listens)\n",
    "print(\"Total number of times each song has been listened to:\", sum(song_listens))\n",
    "print(\"Smallest number of times each song has been listened to.:\", smallest_songs)\n",
    "print(\"Highest number of times each song has been listened to:\", largest_songs)\n",
    "print(\"Average number of times each song has been listened to:\", avg_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7991ae8",
   "metadata": {},
   "source": [
    "### (e) Count the number of users that have listened to each song. What’s the smallest number? The largest number? The average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5dbe3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest number of users that have listened to each song: 6\n",
      "Larget number of users that have listened to each song: 340\n",
      "Average number of users that have listened to each song: 32.07878787878788\n"
     ]
    }
   ],
   "source": [
    "users_per_song = np.sum(X > 0, axis=0)\n",
    "min_users_per_song = np.min(users_per_song)\n",
    "max_users_per_song = np.max(users_per_song)\n",
    "avg_users_per_song = np.mean(users_per_song)\n",
    "print(\"Smallest number of users that have listened to each song:\", min_users_per_song)\n",
    "print(\"Larget number of users that have listened to each song:\", max_users_per_song)\n",
    "print(\"Average number of users that have listened to each song:\", avg_users_per_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afa049",
   "metadata": {},
   "source": [
    "### (f) Count the total number of listens by each user. What’s the smallest number? The largest number? The average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcaa594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of listens by each user [ 33.  56.  34.  11.  45.  40.  14. 131.  19.  12.   8.   9.  53.  12.\n",
      " 409. 159.  94.  24.  14.  13.  10.  10.  50. 108. 116.  10. 103. 143.\n",
      "  52.  96. 123. 377. 481.  13. 297. 376. 142. 150.  92.  43. 688.  81.\n",
      " 220. 156.  33. 601. 480.  10.  22. 163.  52. 100. 584. 158. 103.  15.\n",
      " 180. 282.  56.  86.  97.  44. 249. 307.  64. 209.  66. 353.  39. 419.\n",
      " 419. 205. 157.  18. 335.  69. 289. 403. 269. 163. 151. 167. 246. 103.\n",
      " 121. 356. 234. 335. 322. 111.  88.   9. 128. 131. 102.  17.  50. 132.\n",
      " 106. 211. 155.   6.  38.  75. 334.  36.   7. 152.  95.  25.  13. 132.\n",
      "  71.  44.  40. 158.  15.  98. 149. 115.  88.  87.  73. 238. 183. 478.\n",
      " 242. 247. 413.  85.  11. 264. 235.  17.  18.  12.  40.  41.  17.  23.\n",
      "  22. 141.  27.  40.  74.  71.  37. 131.  34.  10. 107.  79. 111.  16.\n",
      "  62. 115.  61. 176. 186.  25.  70.  37. 515.  84.  36.  32. 152.  69.\n",
      "  23.  16. 228. 186. 418.  59. 121.  26.  40.  16.  33. 125.  10.  17.\n",
      "  16.  56. 320. 205. 147. 246.  73. 345.  81. 128. 278. 108. 151.  70.\n",
      "  20. 132.  23. 373.  95. 105.  82.  28.  38.  23.  22.  14.  32.  70.\n",
      "  28.  13.  14.  65.   6.  55.  14.  29.  11.  21. 102.  37.  40.  20.\n",
      "  19.  28. 115.  17.  69.  22.  22.  12.  19.  53. 208.  92.  46. 186.\n",
      "  40.  21.  27.  32. 125.  61.  19.  29. 142. 218.  50.  20. 125.  60.\n",
      "  15. 232. 209. 265.  15.  68.  11.  12. 114. 136.  32.  14. 123.  24.\n",
      "  47. 280. 321.  79.  37.  84.  42.  26.  92. 160.  22. 121.  18.  33.\n",
      "  32.  13.  20.  21.  54.  38.  73.  51.  61. 145.  56.  24.  83.  75.\n",
      "  10.  21.  21.  10.  16.  23.  15.  21.  20.  14.  63.  15.  10.  16.\n",
      "  15.  17.  78.  66. 120.  57. 103. 162.  18.  92. 181.  26. 165. 120.\n",
      "  56.  12.  43.  44.  54.  30.  28. 416. 230. 394.  61.  39.  28.  74.\n",
      "  13.  54.  24. 217.  10.  17.  17.  51.  16.  25.   9.  70.  17.  69.\n",
      " 307.  80. 375.  38. 361.  38.  44.  10. 149. 158. 258.  79.  22.  15.\n",
      "  30.  18.  23.  30.  71.  34.  57.  19.  10.  10.  39. 243.  57. 133.\n",
      "  63.  14.  26. 294.  28.  35. 120.  42.  13. 113.   9.  14.  23.  35.\n",
      " 135.  12. 289.  16.  92.  38. 182.  60. 276. 239.  50.   9.  44.  85.\n",
      " 296. 170.  20.  14.  35.  59. 111.  14.  94. 119. 124.  78. 247.  16.\n",
      "  73.  41.  56.  31.  24.  26.  35.  25.  60.  34.  38.  41.  28.  55.\n",
      "  80.  89. 108.  20. 112.  27.  97.  78.  56. 102.  24.  84.  91.  21.\n",
      " 158.  31.  68.  14. 118.  24.  21. 114. 120.  14.  46.  28.  58.  14.\n",
      "  24.  61.  66.  77. 131.  25.  29.  28.  36.  69.  55.  49.  53.  56.\n",
      "  77.  27. 115.  32.  81.   8.  17.  61.  89.  22.  51.  29. 111.  74.\n",
      "  92. 103.   7.  21.  15.  16.  26.  93.  30.  98.  30.  18.  57.  34.\n",
      "  21.  13. 106.  17.  85.  36.  11.  39.  28. 116.  49.  10. 205.  16.\n",
      "  54.  97.  65.  16.  13.   9.  17.  47.  11.  45.  89.  32.  39.  54.\n",
      "  27.   6.  12. 339.  89.  17.  29.  20.  14. 117.  24.  59.  29.  62.\n",
      "  70.   9.  18.  92.  53.  58.  15.  11.  16.  49.  10.  25. 223.  22.\n",
      "  23.  15.  51.  10.  13.  12.  19.  62.  35.  18.  16.  70.  15.  23.\n",
      "  38.  22.  66.  20.  14.  46.  69.  30.  13.  19.  20.  19.  22.  36.\n",
      "  30.  19.  12.  13.  42.  14.   9.  31.   8.  63.  21.  23. 133.  95.\n",
      "  45.  47. 150.  72.  80. 109.  31.  64.  78.  35.  29.  45.  31.  39.\n",
      "  29.   8.  22.  90.  10.  25.  39.  22.  13.  27.  27.  22.  35.  15.\n",
      "  35.  32.  15.  21.  28.  80.  30.  12.  45.  11.  21.  10.  18.  59.\n",
      "  18.  77.  59.  53.  30.  30.  38.  18.   9. 102.  30.  24.  36.  19.\n",
      "  26.  16.  12.  24.  22.  23.  11.  30.  21.  17.  21.  55.  24.  19.\n",
      "  15.  46.  22.  12.  21.  52.  23.  74.  12.  21.  40.  18.  21.  15.\n",
      "  42.  38.  82.  27.  72.  36.  31.  13.   9.  11.   9.  20.  16.   9.\n",
      "  21.  24.  14.   9.  35.  63.   8.  24.  31.   7.  42.  13.  53.  31.\n",
      "  21.  82.  55.  14.  56.  22.  10.  10.  13.  13.  10.  22. 149.  12.\n",
      "   7.  31.  30.  21.  35.  12.  11. 101.  11.  23.  16.  17.  14.  15.\n",
      "  18.  15.  19.  18.  23.  23.  19.  15.   8.  19.  12.  28.  12.   6.\n",
      "  54.  24.  18.  25.  14.   8.  14.  13.  15.  15.  19.  18.  13.  21.\n",
      "  15.  11.  23.  14.  13.  13.  39.  14.  23.  13.  32.  16.  14.  22.\n",
      "  13.  18.  52.   8.  14.  37.  15.  13.  39.  12.   8.  13.  17.  56.\n",
      "  19.  16.  18.  29.  16.  18.  23.  18.  25.   7.  10.  23.  29.  33.\n",
      "  14.  16.  16. 100.  15.  14.  30.  12.  71.  19.  10.  42.  19.  13.\n",
      "  16.  17.  11.  13.  34.  10.  26.  14.  13.  17.  16.  24.  16.  21.\n",
      "  22.  32.  13.  15.  35.  22.  25.  23.  13.  20.  13.  12.  10.  10.\n",
      "  13.  16.  14.  11.  21.  21.  20.  24.  11.  22.  15.  28.  28.  65.\n",
      "  19.  14.  42.  16.  12.  42.  22.  37.  23.  24.  21.  19.  10.  21.\n",
      "  26.   7.  25.   8.   8.  32.  15.  20.  18.  12.  24.  22.  39.   8.\n",
      "  20.   8.  18.  24.  16.  47.  47.  70.  32.  16.  13.   8.  12.  18.\n",
      "  14.  17.  16.  16.  12.  15.  11.   8.  17.  13.  18.  21.  10.   9.\n",
      "  18.  20.  13.  13.   9.  54.  23.  12.  15.  24.  10.  19.  18.  30.\n",
      "   7.  22.  18.  10.   8.  28.  23.   7.  13.  10.  23.  12.  31.  11.\n",
      "  18.  16.  14.  12.  22.  14.   9.  12.  13.  13.  10.  12.   8.  23.\n",
      "  13.  11.  13.  15.  10.  13.  13.   7.  11.  23.  11.  34.  12.  18.\n",
      "  12.  20.  14.   8.  16.  84.  34.   9.  14.  52.]\n",
      "Total number of listens by all users 60991.0\n",
      "Smallest number of listens by each user: 2.0\n",
      "Largest number of listens by each user: 293.0\n",
      "Average number of listens by each user: 31.117857142857144\n"
     ]
    }
   ],
   "source": [
    "# (f) Count the total number of listens by each user.\n",
    "listens_per_user = np.sum(X, axis=1)\n",
    "smallest_listens_per_user = np.min(listens_per_user)\n",
    "largest_listens_per_user = np.max(listens_per_user)\n",
    "avg_listens_per_user = np.mean(listens_per_user)\n",
    "print(\"Total number of listens by each user\", song_listens)\n",
    "print(\"Total number of listens by all users\", sum(song_listens))\n",
    "print(\"Smallest number of listens by each user:\", smallest_listens_per_user)\n",
    "print(\"Largest number of listens by each user:\", largest_listens_per_user)\n",
    "print(\"Average number of listens by each user:\", avg_listens_per_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d91884d",
   "metadata": {},
   "source": [
    "### (g) Count the number of songs listened to by each user. What’s the smallest number? The largest number? The average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da3c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest number of songs listened to by each user: 2\n",
      "Largest number of songs listened to by each user: 138\n",
      "Average number of songs listened to by each user: 16.203061224489797\n"
     ]
    }
   ],
   "source": [
    "songs_per_user = np.sum(X > 0, axis=1)\n",
    "smallest_songs_per_user = np.min(songs_per_user)\n",
    "largest_songs_per_user = np.max(songs_per_user)\n",
    "avg_songs_per_user = np.mean(songs_per_user)\n",
    "print(\"Smallest number of songs listened to by each user:\", smallest_songs_per_user)\n",
    "print(\"Largest number of songs listened to by each user:\", largest_songs_per_user)\n",
    "print(\"Average number of songs listened to by each user:\", avg_songs_per_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b79a199",
   "metadata": {},
   "source": [
    "## 4.2 Baseline (No data pre-processing): We will treat the first 1400 rows as the training set, and the remaining rows as the test set. For each of the algorithms below, report the out-of-sample AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8caf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1400, 990)\n",
      "Shape of X_test: (560, 990)\n",
      "Shape of y_train: (1400,)\n",
      "Shape of y_test: (560,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train and test sets\n",
    "X_train = X[:1400]\n",
    "X_test = X[1400:]\n",
    "\n",
    "y_train = y[:1400]\n",
    "y_test = y[1400:]\n",
    "\n",
    "# Verify the shapes of the train and test sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4224d",
   "metadata": {},
   "source": [
    "### (a) Logistic Regression with L1 penalty selected via 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c15fcbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample AUC: 0.7775266638462738\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model with L1 penalty and 5-fold cross-validation\n",
    "log_reg = LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear', scoring='roc_auc', random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the out-of-sample AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"Out-of-sample AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e501f9",
   "metadata": {},
   "source": [
    "### b) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a2610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample AUC for Random Forest: 0.8238516176437843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating the model\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "# # Setting parameters for grid search\n",
    "grid_rf = {'n_estimators': [100, 200, 300], 'max_depth': [None, 5, 10]}\n",
    "\n",
    "# Creating GridSearchCV object with 5-fold cross-validation and ROC AUC scoring\n",
    "cv_rf = GridSearchCV(model_rf, grid_rf, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fitting the model on the training data\n",
    "cv_rf.fit(X_train, y_train)\n",
    "\n",
    "# Calculating out-of-sample AUC using the best estimator from grid search\n",
    "auc_rf = roc_auc_score(y_test, cv_rf.predict_proba(X_test)[:, 1])\n",
    "print(\"Out-of-sample AUC for Random Forest:\", auc_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d15165",
   "metadata": {},
   "source": [
    "### (c) k-NN with both k and the distance function (try euclidean, manhattan, and hamming) selected via 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e489821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample AUC for k-NN: 0.7301997283516288\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9], 'metric': ['euclidean', 'manhattan', 'hamming']}\n",
    "\n",
    "# Create k-NN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba_knn = grid_search.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the out-of-sample AUC\n",
    "auc_knn = roc_auc_score(y_test, y_pred_proba_knn)\n",
    "print(\"Out-of-sample AUC for k-NN:\", auc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91172415",
   "metadata": {},
   "source": [
    "## 4.3: Column Normalization: Repeat part 4.2, this time pre-processing the data beforehand by normalizing the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c4af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16af4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/panktiantani/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/panktiantani/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/panktiantani/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/panktiantani/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/panktiantani/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model with L1 penalty and 5-fold cross-validation\n",
    "log_reg_normalized = LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear', scoring='roc_auc', random_state=42)\n",
    "\n",
    "# Train the model on the normalized training data\n",
    "log_reg_normalized.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Predict probabilities for the normalized test set\n",
    "y_pred_proba_normalized = log_reg_normalized.predict_proba(X_test_normalized)[:, 1]\n",
    "\n",
    "# Calculate the out-of-sample AUC for the normalized dataset\n",
    "auc_normalized = roc_auc_score(y_test, y_pred_proba_normalized)\n",
    "print(\"Out-of-sample AUC for Logistic Regression with normalized data:\", auc_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f5c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUC (Column Normalization): 0.7905254816502402\n"
     ]
    }
   ],
   "source": [
    "# Creating the Random Forest Model\n",
    "model_rf_normalized = RandomForestClassifier()\n",
    "\n",
    "# Setting parameters for grid search\n",
    "grid_rf = {'n_estimators': [100, 200, 300], 'max_depth': [None, 5, 10]}\n",
    "\n",
    "# Creating GridSearchCV object with 5-fold cross-validation and ROC AUC scoring\n",
    "cv_rf_normalized = GridSearchCV(model_rf_normalized, grid_rf, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fitting the model on the normalized training data\n",
    "cv_rf_normalized.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Calculating out-of-sample AUC using the best estimator from grid search\n",
    "auc_rf_normalized = roc_auc_score(y_test, cv_rf_normalized.predict_proba(X_test_normalized)[:, 1])\n",
    "print(\"Out-of-sample AUC for Random Forest with normalized data:\", auc_rf_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76b6a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN AUC (Column Normalization): 0.670571046505869\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9], 'metric': ['euclidean', 'manhattan', 'hamming']}\n",
    "\n",
    "# Create k-NN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the grid search to the normalized data\n",
    "grid_search.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Predict probabilities for the normalized test set\n",
    "y_pred_proba_knn_normalized = grid_search.predict_proba(X_test_normalized)[:, 1]\n",
    "\n",
    "# Calculate the out-of-sample AUC for the normalized dataset\n",
    "auc_knn_normalized = roc_auc_score(y_test, y_pred_proba_knn_normalized)\n",
    "print(\"Out-of-sample AUC for k-NN with normalized data:\", auc_knn_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad0905",
   "metadata": {},
   "source": [
    "## 5.4 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d76c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + k-NN AUC: 0.6062602149472537\n"
     ]
    }
   ],
   "source": [
    "# Defining pipeline with PCA and k-NN\n",
    "pipeline = Pipeline([('pca', PCA()), ('knn', KNeighborsClassifier())])\n",
    "\n",
    "# Grid search with pipeline\n",
    "param_grid = {\n",
    "    'pca__n_components': [10, 20, 30, 40, 50],\n",
    "    'knn__n_neighbors': [3, 5, 7, 9],\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'hamming']\n",
    "}\n",
    "\n",
    "# Using GridSearchCV to find best parameters within specified ranges\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc').fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the best model found by GridSearchCV on the test set\n",
    "y_pred_proba_test = grid_search.predict_proba(X_test)[:, 1]\n",
    "auc_score_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "# Printing best parameters and out-of-sample AUC score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(f\"Out-of-sample AUC Score with PCA and k-NN: {auc_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c3f06",
   "metadata": {},
   "source": [
    "## 4.5 PCA and Column Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca068e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUC (PCA + Column Normalization): 0.72344113714031\n"
     ]
    }
   ],
   "source": [
    "# Defining pipeline with PCA, normalization, and logistic regression\n",
    "pipeline_log_reg = Pipeline([\n",
    "    ('pca', PCA(random_state=1)),\n",
    "    ('std', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(penalty='l1', solver=\"saga\", random_state=123, max_iter=100000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Performing grid search\n",
    "param_grid_log_reg = {\n",
    "    'pca__n_components': [i*10 for i in range(1, 20)],\n",
    "    'logreg__C': np.logspace(-3, 1, 12)\n",
    "}\n",
    "\n",
    "grid_search_log_reg = GridSearchCV(pipeline_log_reg, param_grid=param_grid_log_reg, cv=5, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "grid_search_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating model\n",
    "y_pred_proba_log_reg_test = grid_search_log_reg.predict_proba(X_test)[:, 1]\n",
    "auc_score_log_reg_test = roc_auc_score(y_test, y_pred_proba_log_reg_test)\n",
    "\n",
    "# Printing best parameters and AUC score\n",
    "print(\"Best parameters for Logistic Regression:\", grid_search_log_reg.best_params_)\n",
    "print(\"ROC AUC score for Logistic Regression with L1 penalty selected via 5-fold CV (PCA, Standardized):\", auc_score_log_reg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUC (PCA + Column Normalization): 0.734485661928582\n"
     ]
    }
   ],
   "source": [
    "# Defining pipeline with PCA, normalization, and Random Forest\n",
    "pipeline_rf = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Setting up parameter grid for PCA components\n",
    "param_grid_rf = {'pca__n_components': [10, 20, 30, 40, 50]}\n",
    "\n",
    "# Performing grid search\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='roc_auc').fit(X_train, y_train)\n",
    "\n",
    "# Evaluating model\n",
    "y_pred_proba_rf_test = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "auc_score_rf_test = roc_auc_score(y_test, y_pred_proba_rf_test)\n",
    "\n",
    "# Printing best parameters and out-of-sample AUC score\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "print(f\"Out-of-sample AUC Score with PCA, Normalization, and Random Forest: {auc_score_rf_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb566d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN AUC (PCA + Column Normalization): 0.7038532019216484\n"
     ]
    }
   ],
   "source": [
    "# Defining pipeline with PCA, normalization, and k-NN\n",
    "pipeline_knn = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Setting up parameter grid for PCA components and k-NN parameters\n",
    "param_grid_knn = {\n",
    "    'pca__n_components': [10, 20, 30, 40, 50],\n",
    "    'knn__n_neighbors': [3, 5, 7, 9, 47],\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'hamming']\n",
    "}\n",
    "\n",
    "# Performing grid search\n",
    "grid_search_knn = GridSearchCV(pipeline_knn, param_grid_knn, cv=5, scoring='roc_auc').fit(X_train, y_train)\n",
    "\n",
    "# Evaluating model\n",
    "y_pred_proba_knn_test = grid_search_knn.predict_proba(X_test)[:, 1]\n",
    "auc_score_knn_test = roc_auc_score(y_test, y_pred_proba_knn_test)\n",
    "\n",
    "# Printing best parameters and out-of-sample AUC score\n",
    "print(\"Best parameters for k-NN:\", grid_search_knn.best_params_)\n",
    "print(f\"Out-of-sample AUC Score with PCA, Normalization, and k-NN: {auc_score_knn_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36941449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
